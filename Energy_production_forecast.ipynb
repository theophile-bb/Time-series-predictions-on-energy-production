{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63zLUnqjwtgI"
      },
      "source": [
        "# Energy production & consumption forecast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-sI-4fiFVuC"
      },
      "source": [
        "This project compiles many time series forecasting models and compares their performances. The models introduced are :\n",
        "\n",
        "*   ARIMA\n",
        "*   ARIMAX\n",
        "*   Prophet (Facebook)\n",
        "*   LSTM\n",
        "*   Chronos (Amazon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dtt-PL18I7nU"
      },
      "source": [
        "Done using the Our World in Data Energy dataset : https://github.com/owid/energy-data?tab=readme-ov-file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgoXt1dlwnCZ"
      },
      "source": [
        "## Imports & prerequisits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lGrJYXWqzPDI"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/theophile-bb/Time-series-predictions-on-energy-production.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Time-series-predictions-on-energy-production"
      ],
      "metadata": {
        "id": "dq6nupwqixxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "JjP2K1fBhqjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"src\")"
      ],
      "metadata": {
        "id": "Con8gCpITnBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mx4QWeggb3e4"
      },
      "outputs": [],
      "source": [
        "# Utils\n",
        "\n",
        "from utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQh_3bAWl3Q1"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "#pd.set_option('display.max_rows', None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"data/energy_sample.json\""
      ],
      "metadata": {
        "id": "S1frrTA_O1dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsutaIItw27z"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pVXdFSyfRx_"
      },
      "source": [
        "Let's start by reading the data from the json and putting the dataframe into shape :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldjrkS9EDv2J"
      },
      "outputs": [],
      "source": [
        "data = load_json(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKY2vTYCD1dm"
      },
      "outputs": [],
      "source": [
        "df = create_df(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Vm6JfMrjoG_"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QcXpOKg4Stj"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "figs = []"
      ],
      "metadata": {
        "id": "cXQQIt7ccfxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1uLcKY67cNL"
      },
      "source": [
        "## Production Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rO-E-PCwS3n"
      },
      "source": [
        "The goal here is to proceed manualy to try and forecast the production for one of the energy sources.\n",
        "\n",
        "To do so we'll try multiple forecasting models and see how they perform to forecast with our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI3ZAqVVftGs"
      },
      "source": [
        "As a starter we'll begin by sticking to only the USA and we'll study the oil, gas and coal productions since year 1900."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHoRrz_T4Tkh"
      },
      "outputs": [],
      "source": [
        "countries = [\"United States\"]\n",
        "col = ['region', 'coal_production', 'oil_production', 'gas_production']\n",
        "\n",
        "df_country = get_countries(df, countries)\n",
        "df_production = get_columns(df_country, col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_dQ8dPGwI7M"
      },
      "outputs": [],
      "source": [
        "plot_total_production = plot_graph(df_production,\"Production over time\")\n",
        "figs.append(plot_total_production)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9NOh1DWBWiy"
      },
      "source": [
        "### ARIMA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"ARIMA\""
      ],
      "metadata": {
        "id": "w4jFoAjthjTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NalYvj4KGz_i"
      },
      "source": [
        "The ARIMA models combine two models and one method. These are:\n",
        "\n",
        "*   Auto Regression(AR)\n",
        "*   Moving Average(MA)\n",
        "*   Differencing for stationarity(I)\n",
        "\n",
        "A nonseasonal ARIMA model is classified as an \"ARIMA(p,d,q)\" model, where: p is the number of autoregressive terms(AR), d is the number of nonseasonal differences needed for stationarity(I), and q is the number of lagged forecast errors in the prediction equation(MA)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcNXGg0gKhRT"
      },
      "source": [
        "One of the preprocessing steps is to determine the optimal orders **(p, d, q)** of our ARIMA model. The simplest one is the order of differencing d as this can be verified by carrying out a statistical test for stationarity. The most popular one is the Augmented Dickey-Fuller (ADF), where the null hypothesis is that the time series is not stationary.\n",
        "\n",
        "d refers to the number of differencing transformations required by the time series to get stationary. So we can use pandas 'diff()' function once or more and recall stationarity function to find the d-value.  If the P-value of Dickey-Fuller test is less than 0.05, the column is stationary, otherwise it is not stationary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmvLermehMsc"
      },
      "outputs": [],
      "source": [
        "col = 'coal_production'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI3TQTd0gvBZ"
      },
      "source": [
        "The function stationarity will ease the process by returning d (number of differenciations) and the associated P-value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "729z2ZsD8QtN"
      },
      "outputs": [],
      "source": [
        "diff_col, d = stationarity(df_production[col])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYvjqTRjLDv0"
      },
      "source": [
        "The autoregressive and moving-average orders (p,q) can be deduced by analysing the partial autocorrelation function (PACF) and autocorrelation function respectively. The gist of of this method is to plot a correlogram of the various lags/forecast errors of the time series to determine which are statistically significant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pF2qxYJPLOOA"
      },
      "outputs": [],
      "source": [
        "plot_autocorrelation = plot_acf(diff_col)\n",
        "plot_partial_autocorrelation = plot_pacf(diff_col)\n",
        "\n",
        "figs.append(plot_autocorrelation)\n",
        "figs.append(plot_partial_autocorrelation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIE0Edk2xJlr"
      },
      "source": [
        "We can use the Autocorrelation plot to get q and the Partial Autocorrelation one to get p."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQweA97sjDhc"
      },
      "source": [
        "We then split our dataset into training and testing set :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTeddE_vLZZ9"
      },
      "outputs": [],
      "source": [
        "train, test = split_data(df_production, 0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzx-zHzcjH7M"
      },
      "source": [
        "We define the model with the parameters p, d, q. If p and q are equal to 0 it gives us an ARIMA(0, 1, 0). It then becomes an ARMA(0, 0) when differenced, which is random, uncorrelated, noise (random walk). The sum of noise terms has a mean of 0 : the expected position is still the starting point, but the variance around it increases over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_Pc9xOpOQAR"
      },
      "outputs": [],
      "source": [
        "model_fit = train_ARIMA(train, col, 0,d,0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvH8zCABi8UU"
      },
      "source": [
        "We use the model to forecast on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bm3LVxTj39gX"
      },
      "outputs": [],
      "source": [
        "test_forecast = predict_ARIMA(model_fit, test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTaBGfD0jKUi"
      },
      "source": [
        "Finally we can plot the predictions on the test set and compare it with the actual ones :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YVXUW4h4bWY"
      },
      "outputs": [],
      "source": [
        "title = f\"Production and prediction with {model_name} on Test set\"\n",
        "plot_ARIMA_test = plot_graph(test_forecast, title, ['coal_production','forecast'])\n",
        "figs.append(plot_ARIMA_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng_RLvaxlkfv"
      },
      "source": [
        "Note : We can also use auto_arima to find the optimal p, d, q for our model, which we will use in the coming part : ARIMAX."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP9wKbVWyK2L"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lLJg2hmAq3s"
      },
      "source": [
        "### ARIMAX"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"ARIMAX\""
      ],
      "metadata": {
        "id": "DB2lticgnzQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fcen9A8jEhUV"
      },
      "source": [
        "The **ARIMAX (AutoRegressive Integrated Moving Average with Exogenous Variables)** model is an extension of ARIMA that incorporates exogenous variables (X variables) to improve forecasting accuracy. It is a good model to use when there is an external factor (exogenous variable) influencing the time series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvqv8AZQA86C"
      },
      "source": [
        "First we'll test the model by training it on a training set and testing it with a test set. We are going to partition both the endogenous and exogenous values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTWUes6dHD1q"
      },
      "outputs": [],
      "source": [
        "endog_col = col\n",
        "exog_col = ['gdp', 'population', 'primary_energy_consumption', 'oil_production', 'gas_production']\n",
        "\n",
        "endog, exog = initialize_endog_exog(df_country,endog_col, exog_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf3sMEbDL4YU"
      },
      "outputs": [],
      "source": [
        "endog_train, endog_test = split_data(endog, 0.8)\n",
        "exog_train, exog_test = split_data(exog, 0.8)\n",
        "\n",
        "model = train_SARIMAX(endog_train, exog_train)\n",
        "\n",
        "results = predict_SARIMAX(model, exog_test, len(exog_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26vN-GiIAy2b"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(data={'actual': list(endog_test), 'predicted': list(results)}, index=endog_test.index)\n",
        "\n",
        "title = f\"Production and prediction with {model_name} on Test set\"\n",
        "plot_ARIMAX_test = plot_graph(results_df, title , ['actual','predicted'])\n",
        "figs.append(plot_ARIMAX_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbkl3pf6CGvU"
      },
      "source": [
        "We are now going to try and predict the future values for the coming years. To do so we'll need the exogenous values for these years.\n",
        "\n",
        "We are going to approximate each of the future exogneous values (column) by using a simple linear regression with polynomial features. This model isn't optimal but it is quite simple and very well fitting for values with an exponential growth such as 'gdp' or 'population'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ex64qiQDsut"
      },
      "source": [
        "Note that we use the **ReLu (Rectified Linear Unit)** function to prevent negative predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRZoTwiRl-ED"
      },
      "outputs": [],
      "source": [
        "exog_pred = predict_exog(exog)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYhsFgoJENJY"
      },
      "source": [
        "Now that we have our predicted exogenous values we can train the ARIMAX with the endogenous and exogenous values and then predict using the predicted exogenous values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OsbWZBllMYF"
      },
      "outputs": [],
      "source": [
        "model = train_SARIMAX(endog, exog)\n",
        "\n",
        "results = predict_SARIMAX(model, exog_pred, len(exog_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3BJ5I37K6hG"
      },
      "outputs": [],
      "source": [
        "data_plot = format_data_plot(endog)\n",
        "forecast_plot = format_forecast_plot(results, df_production, len(results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Xv3AVLGFt4f"
      },
      "outputs": [],
      "source": [
        "plot_ARIMAX_forecast = plot_forecasts(data_plot, forecast_plot, col, model_name)\n",
        "figs.append(plot_ARIMAX_forecast)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e95oaZJ69bAp"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9easGK-B9cF8"
      },
      "source": [
        "### Prophet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"Prophet\""
      ],
      "metadata": {
        "id": "fP0SWxv6ol9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grbFUasVG1si"
      },
      "source": [
        "Prophet is an additive time series forecasting model that’s designed to work well with data that has:\n",
        "\n",
        "*   Seasonality (daily, weekly, yearly patterns).\n",
        "*   Trends (growth, decline, plateaus).\n",
        "*   Holidays/Special Events (big spikes or dips).\n",
        "\n",
        "It’s built to be robust to missing data and outliers, which is a common headache with other models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fztFYJXjMJqw"
      },
      "outputs": [],
      "source": [
        "prophet_df = format_Prophet(df_country, col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaff1mfXrAhW"
      },
      "source": [
        "We disable seasonality because we have no use of it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6Y9OHUyN5Ch"
      },
      "outputs": [],
      "source": [
        "period = 10\n",
        "\n",
        "model = fit_Prophet(prophet_df)\n",
        "results = predict_Prophet(model, period)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "z24iUalJrl-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1Oyo0RarHKw"
      },
      "source": [
        "We can try to predict for the next 10 years :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYDOJXO3Elpj"
      },
      "outputs": [],
      "source": [
        "data_plot = format_data_plot(df_production[col])\n",
        "forecast_plot = format_Prophet_plot(df_production, results, period)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeE33SBLBDsu"
      },
      "outputs": [],
      "source": [
        "plot_prophet_forecast = plot_forecasts(data_plot, forecast_plot, col, model_name)\n",
        "figs.append(plot_prophet_forecast)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr2U7DokG-o6"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oECjQUUHAV9"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"LSTM\""
      ],
      "metadata": {
        "id": "_NM7DCQLo3ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-abBT5crjUE"
      },
      "source": [
        "Long Short-Term Memory is a type of Recurrent Neural Network (RNN). LSTM learns from past values and patterns directly which makes it good when past values influence future values.\n",
        "\n",
        "Regular RNNs struggle with long-term dependencies whereas the LSTM has a memory cell that helps retain information over long periods.\n",
        "\n",
        "It decides what to remember and what to forget using three gates:\n",
        "\n",
        "*   Forget Gate\t: Decides what past info to forget.\n",
        "*   Input Gate : Decides what new info to store.\n",
        "*   Output Gate\t: Decides what to output based on memory.\n",
        "\n",
        "LSTM remembers long-term trends but adapts when patterns change."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "111qID-27vbM"
      },
      "source": [
        "###  Multi-step-ahead forecast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jn6GNuRRxCpW"
      },
      "source": [
        "We predict multiple future steps directly on the entire horizon (e.g., next 5 years) at once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRG5bTzi2ji_"
      },
      "outputs": [],
      "source": [
        "  scaled_data, scaler = scale_data(df_production, col)\n",
        "  train, test = split_data(scaled_data, 0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rtbP8eb9wYw"
      },
      "outputs": [],
      "source": [
        "seq_length = 3\n",
        "horizon = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxpMHIUqMMy3"
      },
      "outputs": [],
      "source": [
        "model = fit_LSTM(train, test, seq_length, horizon)\n",
        "\n",
        "results = flatten_prediction(scaled_data, seq_length, model, scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exGpCvdUHLmb"
      },
      "outputs": [],
      "source": [
        "data_plot = format_data_plot(df_production[col])\n",
        "forecast_plot = format_forecast_plot(results, df_production, len(results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQ8XN_cHNQXY"
      },
      "outputs": [],
      "source": [
        "plot_LSTM_forecast = plot_forecasts(data_plot, forecast_plot, col, model_name)\n",
        "figs.append(plot_LSTM_forecast)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhC-BB9LMNMR"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyS1a85vGz3P"
      },
      "source": [
        "### Chronos Bolt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"Chronos\""
      ],
      "metadata": {
        "id": "DmZeQ9wtpEeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TtcSkn3v1I1"
      },
      "source": [
        "# *Note : Requires Python 3.10 to work*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbExW2Oc2vck"
      },
      "source": [
        "Chronos-Bolt is a family of pretrained time series forecasting models which can be used for zero-shot forecasting. It is based on the T5 encoder-decoder architecture and has been trained on nearly 100 billion time series observations. It chunks the historical time series context into patches of multiple observations, which are then input into the encoder. The decoder then uses these representations to directly generate quantile forecasts across multiple future steps—a method known as direct multi-step forecasting.\n",
        "\n",
        "References :\n",
        "\n",
        "https://huggingface.co/autogluon/chronos-bolt-small\n",
        "\n",
        "https://github.com/amazon-science/chronos-forecasting/tree/main\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1K3P-BJ3Mfm"
      },
      "source": [
        "Let's start by training a chronos with a train set and see its performances on a test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYPYgFb7LUcM"
      },
      "outputs": [],
      "source": [
        "ChronosData = format_Chronos(df_production, col)\n",
        "\n",
        "train, test = split_data(ChronosData, 0.8)\n",
        "\n",
        "period = len(test)\n",
        "model = fit_Chronos(train, period)\n",
        "\n",
        "print(ChronosData.index.get_level_values(\"timestamp\").freq)\n",
        "\n",
        "results_train = predict_Chronos(model, train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test['forecast'] = results_train['mean']\n",
        "test[\"year\"] = test.index.get_level_values(\"timestamp\").year\n",
        "test = test.reset_index()"
      ],
      "metadata": {
        "id": "jH-lmF1Nguxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title = f\"Production and prediction with {model_name} on Test set\"\n",
        "plot_chronos_test = plot_graph(test, title, ['target','forecast'])\n",
        "figs.append(plot_chronos_test)"
      ],
      "metadata": {
        "id": "L8PZaTDeh4P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjXDZraM3ZuA"
      },
      "source": [
        "Then we can forecast for future years"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWBjoRkUNsQR"
      },
      "outputs": [],
      "source": [
        "period = 10\n",
        "model = fit_Chronos(ChronosData, period)\n",
        "results = predict_Chronos(model, ChronosData)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_plot = format_data_plot(df_production[col])\n",
        "forecast_plot = format_forecast_plot(results['mean'], df_production, period)"
      ],
      "metadata": {
        "id": "BvdKtmTQWiAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_chronos_forecast = plot_forecasts(data_plot, forecast_plot, col, model_name)\n",
        "figs.append(plot_chronos_forecast)"
      ],
      "metadata": {
        "id": "alBR-7ulgDJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3RVDQ8B8TsU"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_figs(figs, folder=\"plots\")"
      ],
      "metadata": {
        "id": "cUnJNVhBXXlh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}